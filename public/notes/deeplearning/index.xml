<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Learning on Burhan Usman</title>
    <link>https://www.burhanusman.com/notes/deeplearning/</link>
    <description>Recent content in Deep Learning on Burhan Usman</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 06 Apr 2019 14:53:47 +0530</lastBuildDate>
    
	<atom:link href="https://www.burhanusman.com/notes/deeplearning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Notes from Karpathy&#39;s Article on training NNs</title>
      <link>https://www.burhanusman.com/notes/deeplearning/recipe_karpathy/</link>
      <pubDate>Fri, 26 Apr 2019 21:54:24 +0530</pubDate>
      
      <guid>https://www.burhanusman.com/notes/deeplearning/recipe_karpathy/</guid>
      <description>Two Observations he make:  Neural network training is tough and cannot be easily abstracted A lot of things can wrong go while training a nueral network   Now, suffering is a perfectly natural part of getting a neural network to work well, but it can be mitigated by being thorough, defensive, paranoid, and obsessed with visualizations of basically every possible thing.
 The recipe:  If writing your neural net code was like training one, youâ€™d want to use a very small learning rate and guess and then evaluate the full test set after every iteration.</description>
    </item>
    
    <item>
      <title>Pytorch Toy Classification</title>
      <link>https://www.burhanusman.com/notes/deeplearning/toy-classification-pytorch/</link>
      <pubDate>Sat, 06 Apr 2019 21:54:24 +0530</pubDate>
      
      <guid>https://www.burhanusman.com/notes/deeplearning/toy-classification-pytorch/</guid>
      <description>Making a one-hidden layer neural network with pytorch Importing the required libraries import numpy as np from sklearn.model_selection import train_test_split from sklearn.datasets import make_moons from sklearn.metrics import accuracy_score, precision_score, recall_score import matplotlib.pyplot as plt import seaborn as sns import torch import torch.nn as nn import torch.nn.functional as F from torch.autograd import Variable from torch.distributions import constraints Making a toy dataset We use the make moons dataset from Scikit-Learn
X, Y = make_moons(noise=0.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://www.burhanusman.com/notes/deeplearning/pytorch_notes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://www.burhanusman.com/notes/deeplearning/pytorch_notes/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>